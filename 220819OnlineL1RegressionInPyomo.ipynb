{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3171ab0",
   "metadata": {},
   "source": [
    "To install Pyomo:  conda install -c conda-forge pyomo \n",
    "\n",
    "To install glpk solver:  conda install -c conda-forge glpk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee6489ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyomo.environ as pyo\n",
    "from pyomo.opt import SolverFactory\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa2258a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional solver imports for Pyomo\n",
    "from gurobipy import *\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import mosek\n",
    "import xpress\n",
    "from pyomo.core.expr.current import identify_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c02bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataForL1FromDataFrame(df):\n",
    "    explanatoryTraining = []\n",
    "    nObservations = len(df['Response'])\n",
    "    nExplanatorys = len(df.columns)-1\n",
    "    responseTraining = df['Response'].tolist()\n",
    "    for i in range(1,len(df.columns)):\n",
    "        explanatoryTraining.append(df[f'Explanatory{i}'].tolist())\n",
    "            \n",
    "    return explanatoryTraining, responseTraining, nObservations, nExplanatorys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35a480fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inertTestDataSeries(dfOriginal,dfSeriesToTest,betaValues,dualVariablesFitted, df_BasisX1_inv):\n",
    "    #df contains a set of points each of which will be inert tested and a list containing inertness of each point as True or False will be returned.\n",
    "    #dualVariablesFitted=[dualVariableValuesOriginal[i] for i in indexesOfFittedPointsOriginal]\n",
    "    #inertTestListReturn=[]\n",
    "    \n",
    "    tempResponse=dfSeriesToTest[0].copy()\n",
    "    dfSeriesToTest[0]=1\n",
    "    \n",
    "    pointsDistanceToL1Hyperplane = tempResponse-np.sum(np.matmul(dfSeriesToTest,betaValues))\n",
    "    pointsPositionToL1Hyperplane = np.sign(pointsDistanceToL1Hyperplane)\n",
    "    #pointsPositionToL1Hyperplane = np.sum(df_BasisX1_inv[len]\n",
    "    #print('len(dualVariablesFitted): ', len(dualVariablesFitted),'len(dfSeriesToTest): ', len(dfSeriesToTest),'len(df_BasisX1_inv): ', len(df_BasisX1_inv), )\n",
    "    inertnessValue = dualVariablesFitted-pointsPositionToL1Hyperplane*np.matmul(np.asarray(dfSeriesToTest),np.asarray(df_BasisX1_inv))\n",
    "    \n",
    "    #This check process can be done faster\n",
    "    inertnessOfaPoint = inertnessValue[(inertnessValue>=-1) & (inertnessValue<=1)]\n",
    "    pointIsInert = len(inertnessOfaPoint)==len(inertnessValue)\n",
    "    #inertTestListReturn.append(pointIsInert)\n",
    "    \n",
    "    return pointIsInert, abs(pointsDistanceToL1Hyperplane), inertnessValue, np.sign(pointsDistanceToL1Hyperplane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd2a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated on 8/26/22 pyo.VarList is tested. Indexing starts at 1, this is incorparated to the code in this cell\n",
    "# L1 REGRESSION INITIAL SOLVING FUNCTION\n",
    "def L1RegressionModelNormalStartPyomo (explanatoryTraining,responseTraining,manualBetaValues): #This function has two if statement in it, it should not be used for ultimate speed comparison\n",
    "    #Below different options for data creation are created depending on the parameters passed with L1RegressionModel.\n",
    "    functionStartTime=time.perf_counter()\n",
    "    \n",
    "    nObservations=len(responseTraining)\n",
    "    nExplanatorys=len(explanatoryTraining) \n",
    "#--------------------------------------------------------------------------------------------------------------------------        \n",
    "    model = pyo.ConcreteModel()\n",
    "    model.betaValues = pyo.VarList()\n",
    "    for i in range(len(explanatoryTraining)+1):\n",
    "        model.betaValues.add()\n",
    "    #model.betaValues = pyo.Var(range(len(explanatoryTraining)+1))\n",
    "    #model.zPlus = pyo.Var(range(len(explanatoryTraining[0])), domain=pyo.NonNegativeReals)\n",
    "    #model.zMinus = pyo.Var(range(len(explanatoryTraining[0])), domain=pyo.NonNegativeReals)\n",
    "    model.zPlus = pyo.VarList(domain=pyo.NonNegativeReals)\n",
    "    for i in range(len(explanatoryTraining[0])):\n",
    "        model.zPlus.add()\n",
    "    model.zMinus = pyo.VarList(domain=pyo.NonNegativeReals)\n",
    "    for i in range(len(explanatoryTraining[0])):\n",
    "        model.zMinus.add()\n",
    "\n",
    "\n",
    "    #Objective function\n",
    "    temp_expr = 0\n",
    "    for i in range(nObservations):               \n",
    "        temp_expr+=(model.zPlus[i+1]+model.zMinus[i+1])\n",
    "    model.obj = pyo.Objective(expr = temp_expr, sense=pyo.minimize)\n",
    "    \n",
    "    #Constraints\n",
    "    model.ConstraintSet=pyo.ConstraintList()\n",
    "    for i in range(nObservations):\n",
    "        #Babayaga\n",
    "        #for j in range(len(explanatoryTraining)):\n",
    "        #    print('i: ', i, '\\n type(model.betaValues[1])', type(model.betaValues[1]), '\\n type(model.zPlus[i+1])',\\\n",
    "        #          type(model.zPlus[i+1]), '\\n type(model.zMinus[i+1])', type(model.zMinus[i+1]),\\\n",
    "        #          '\\n type(model.betaValues[j+2])', type(model.betaValues[j+2]),\\\n",
    "        #          '\\n type(explanatoryTraining[j][i])', type(explanatoryTraining[j][i]), explanatoryTraining[j][i],\\\n",
    "        #          '\\n type(len(explanatoryTraining))', type(len(explanatoryTraining)),\\\n",
    "        #         '\\n type(responseTraining[i])', type(responseTraining[i]))\n",
    "        model.ConstraintSet.add(model.betaValues[1]+model.zPlus[i+1]-model.zMinus[i+1]+ \\\n",
    "    sum(model.betaValues[j+2]*explanatoryTraining[j][i] for j in range(len(explanatoryTraining)))==responseTraining[i])\n",
    "    #def constraint_rule(m, i):\n",
    "    #    return m.betaValues[0]+m.zPlus[i+1]-m.zMinus[i+1]+ \\\n",
    "    #sum(m.betaValues[j+1]*explanatoryTraining[j][i] for j in range(len(explanatoryTraining)))==responseTraining[i]\n",
    "    #Adds sets of constraints having indices: range(len(explanatoryTraining[0])) by calling the constraint rule above.\n",
    "    #model.ConstraintSet = pyo.Constraint(range(len(explanatoryTraining[0])), rule=constraint_rule)\n",
    "    \n",
    "    #Manuel beta values\n",
    "    if len(manualBetaValues) != 0:\n",
    "        def manual_constraint_rule(m, i):\n",
    "            return m.betaValues[i] == manualBetaValues[i]\n",
    "        model.ManualConstraintSet = pyo.Constraint(range(len(explanatoryTraining)+1), rule=manual_constraint_rule)\n",
    "    \n",
    "    model.dual = pyo.Suffix(direction=pyo.Suffix.IMPORT)\n",
    "    opt = pyo.SolverFactory('glpk')\n",
    "    #model.varList = pyo.VarList()\n",
    "    #opt = pyo.SolverFactory('scip', executable=\"./scip\")\n",
    "    result=opt.solve(model)\n",
    "    \n",
    "    functionEndTime=time.perf_counter()\n",
    "    functionRunTime=functionEndTime-functionStartTime\n",
    "    return model, functionRunTime,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2594dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated on 8/26/22 pyo.VarList is tested. \n",
    "# Indexing starts at 1, this is incorparated to the code in this cell.\n",
    "# Python related indexing will start with zero but pyomo relating indexing will start with 1.\n",
    "# This cell reconciles the discrepency mentioned above.\n",
    "\n",
    "def streamingL1RegressionColdStartPyomo(dfOriginal):\n",
    "    #This function takes the historical data set and run L1 regression iteratively on it starting with the first m x m matrix exert of the original data set.\n",
    "    #Start function timer\n",
    "    print('streamingL1RegressionColdStartPyomo is initiated')\n",
    "    functionStartTime=time.perf_counter()\n",
    "    \n",
    "    #Initialize variables\n",
    "    manualBetaValues=list()\n",
    "    totalSolverRunTime=0\n",
    "    totalIterationCount=0    \n",
    "    \n",
    "    #Describe parameters\n",
    "    lenOriginal=dfOriginal.shape[0]\n",
    "    dimensionL1=dfOriginal.shape[1]\n",
    "    print('lenOriginal: ', lenOriginal, 'dimensionL1: ', dimensionL1)\n",
    "    totalNumberOfPointsToAdd=lenOriginal-dimensionL1+1\n",
    "    \n",
    "    #Partition the original data set into m by m and n-m by m sets. \n",
    "    dfStreaming = dfOriginal.iloc[0:dimensionL1].copy()\n",
    "    dfNotStreamed = dfOriginal.iloc[dimensionL1:lenOriginal].copy()\n",
    "    \n",
    "    \n",
    "    #----Solve L1 regression on the initial data set which is m by m--------\n",
    "    explanatoryTraining, responseTraining, nObservations, nExplanatorys = createDataForL1FromDataFrame(dfStreaming)\n",
    "    \n",
    "    modelX, functionRunTimeNormal, results=L1RegressionModelNormalStartPyomo (explanatoryTraining,responseTraining,manualBetaValues)\n",
    "    \n",
    "    functionStartTime=time.perf_counter()\n",
    "    instance = modelX.create_instance()\n",
    "\n",
    "    #----Start iterating on the rest of the data set one by one simulating streaming data------\n",
    "    for index, row in dfNotStreamed.iterrows():\n",
    "        \n",
    "        #Add a row to data frame from back. \n",
    "        dfStreaming.loc[len(dfStreaming)]=row.copy()\n",
    "        \n",
    "        #Create a new variable in zPlus and zMinus variables\n",
    "        #print('number of points: ', index+1)\n",
    "        #print('len(zPlus): ',len(modelX.zPlus))\n",
    "        #new_v = modelX.varList.add()\n",
    "        instance.zPlus.add()\n",
    "        instance.zMinus.add()\n",
    "\n",
    "\n",
    "        #Create the new set of constraints for L1Model\n",
    "        temp_sum = 0\n",
    "        temp_sum += instance.betaValues[1]\n",
    "        for j in range(dimensionL1-1):\n",
    "            temp_sum += instance.betaValues[j+2]*row[j+1]\n",
    "        temp_sum += instance.zPlus[index+1]-instance.zMinus[index+1]\n",
    "        instance.ConstraintSet.add(temp_sum == row[0])\n",
    "\n",
    "        #Update the objective\n",
    "        instance.obj.expr += (instance.zPlus[index+1] + instance.zMinus[index+1])\n",
    "\n",
    "        #Solve the updated model - warmstart toogle is off\n",
    "        opt = pyo.SolverFactory('glpk')\n",
    "        results = opt.solve(instance)\n",
    "        #opt.solve(instance)\n",
    "        #modelX.display()\n",
    "        #print(results)\n",
    "        if index%500==0:\n",
    "            print(f'{index}th point processed in streamingL1RegressionColdStartPyomo')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    #print('Beta0: ', pyo.value(instance.betaValues[1]), 'Beta1: ', pyo.value(instance.betaValues[2]),\\\n",
    "    #      'Beta2: ', pyo.value(instance.betaValues[3]), 'Beta3: ', pyo.value(instance.betaValues[4]))            \n",
    "            \n",
    "    #print all (\"Duals\") \n",
    "    #for c in instance.component_objects(pyo.Constraint, active=True):\n",
    "    #    print (\"   Constraint\",c)\n",
    "    #    for index in c:\n",
    "    #        print (\"      \", index, instance.dual[c[index]])\n",
    "        \n",
    "    #Print all variables\n",
    "    #for v in instance.component_objects(pyo.Var, active=True):\n",
    "    #    print(\"Variable\",v)  \n",
    "    #    for index in v:\n",
    "    #        print (\"   \",index, pyo.value(v[index]))\n",
    "    \n",
    "    #varsConstrains = identify_variables(instance.ConstraintSet)\n",
    "    #print('varsConstrains: ', varsConstrains)\n",
    "    functionEndTime=time.perf_counter()\n",
    "    functionRunTime=functionEndTime-functionStartTime\n",
    "    functionReturn={'functionRunTime': functionRunTime}\n",
    "    return functionReturn , results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f9d371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 08/30/22\n",
    "\n",
    "def streamingL1RegressionColdInertPyomo(dfOriginal):\n",
    "    #This function takes the historical data set and run L1 regression iteratively on it starting with the first m x m matrix exert of the original data set.\n",
    "    #Start function timer\n",
    "    print('streamingL1RegressionColdInertPyomo is initiated')\n",
    "    functionStartTime=time.perf_counter()\n",
    "    \n",
    "    #Initialize variables\n",
    "    manualBetaValues=list()\n",
    "    totalSolverRunTime=0\n",
    "    totalIterationCount=0\n",
    "    notInertPointIndexes=[]\n",
    "    differentialListWhenArrivalIsNotInert=[]\n",
    "    differentialList=[]\n",
    "    inertRunList=[]\n",
    "    \n",
    "    #Describe parameters\n",
    "    lenOriginal=dfOriginal.shape[0]\n",
    "    dimensionL1=dfOriginal.shape[1]\n",
    "    nDimensionRange= range(dimensionL1)\n",
    "    print('lenOriginal: ', lenOriginal, 'dimensionL1: ', dimensionL1)\n",
    "    totalNumberOfPointsToAdd=lenOriginal-dimensionL1+1\n",
    "    \n",
    "    #Partition the original data set into m by m and n-m by m sets. \n",
    "    dfStreaming = dfOriginal.iloc[0:dimensionL1].copy()\n",
    "    dfNotStreamed = dfOriginal.iloc[dimensionL1:lenOriginal].copy()\n",
    "    \n",
    "    \n",
    "    #----Solve L1 regression on the initial data set which is m by m--------\n",
    "    explanatoryTraining, responseTraining, nObservations, nExplanatorys = createDataForL1FromDataFrame(dfStreaming)\n",
    "    \n",
    "    modelX, functionRunTimeNormal, results=L1RegressionModelNormalStartPyomo (explanatoryTraining,responseTraining,manualBetaValues)\n",
    "    \n",
    "    differential=0\n",
    "    differentialList.append(differential)\n",
    "    \n",
    "    functionStartTime=time.perf_counter()\n",
    "    instance = modelX.create_instance()\n",
    "    \n",
    "    #Get the indexes of the fitted points\n",
    "    indexesOfFittedPoints=[]\n",
    "    for i in np.arange(nObservations):\n",
    "        if (pyo.value(instance.zPlus[i+1]) + pyo.value(instance.zMinus[i+1])) == 0:\n",
    "            indexesOfFittedPoints.append(i)\n",
    "    #print('len(indexesOfFittedPoints)1: ', len(indexesOfFittedPoints))\n",
    "    #Get the L1 regression hyperplane parameters - beta values \n",
    "    betaValues=[]\n",
    "    for i in nDimensionRange:\n",
    "        betaValues.append(pyo.value(instance.betaValues[i+1]))\n",
    "        \n",
    "        \n",
    "        \n",
    "    #get basisX1 inverse    \n",
    "    dfBasisX1=dfOriginal.iloc[indexesOfFittedPoints].copy()\n",
    "    dfBasisX1['Response']=1\n",
    "    df_BasisX1_inv = pd.DataFrame(np.linalg.pinv(dfBasisX1.values), dfBasisX1.columns, dfBasisX1.index)\n",
    "    \n",
    "    # Get the dual variable values corresponding to the fitted points\n",
    "    dualVariableValuesFittedPoints=[]\n",
    "    for c in instance.component_objects(pyo.Constraint, active=True):\n",
    "        for index in indexesOfFittedPoints:\n",
    "            dualVariableValuesFittedPoints.append(instance.dual[c[index+1]])\n",
    "    \n",
    "   \n",
    "    #----Start iterating on the rest of the data set one by one simulating streaming data------\n",
    "    #You can save some time using index instead of counter\n",
    "    inertRunAmount=0\n",
    "    #----Start iterating on the rest of the data set one by one simulating streaming data------\n",
    "    for index, row in dfNotStreamed.iterrows():\n",
    "        if index%500==0:\n",
    "            print(f'{index}th point processed in streamingL1RegressionColdInertPyomo')\n",
    "        #Add a row to data frame from back. \n",
    "        dfStreaming.loc[len(dfStreaming)]=row.copy()\n",
    "        \n",
    "        instance.zPlus.add()\n",
    "        instance.zMinus.add()\n",
    "\n",
    "\n",
    "        #Create the new set of constraints for L1Model\n",
    "        temp_sum = 0\n",
    "        temp_sum += instance.betaValues[1]\n",
    "        for j in range(dimensionL1-1):\n",
    "            temp_sum += instance.betaValues[j+2]*row[j+1]\n",
    "        temp_sum += instance.zPlus[index+1]-instance.zMinus[index+1]\n",
    "        instance.ConstraintSet.add(temp_sum == row[0])\n",
    "\n",
    "        #Update the objective\n",
    "        instance.obj.expr += (instance.zPlus[index+1] + instance.zMinus[index+1])\n",
    "        \n",
    "\n",
    "        inertResult, estimationErrorForTheNewPoint, dualVariableValuesFittedPoints, positionOfArrival = \\\n",
    "        inertTestDataSeries(dfStreaming,row,betaValues,dualVariableValuesFittedPoints, df_BasisX1_inv)\n",
    "        \n",
    "\n",
    "        if inertResult == False:\n",
    "            \n",
    "            nObservations=dfStreaming.shape[0]\n",
    "            inertRunList.append(inertRunAmount)\n",
    "            inertRunAmount=0\n",
    "            notInertPointIndexes.append(index)\n",
    "            \n",
    "            opt = pyo.SolverFactory('glpk')\n",
    "            results = opt.solve(instance)    \n",
    "            \n",
    "            indexesOfFittedPoints=[]\n",
    "            indexesOfUnfittedPoints=[]\n",
    "            #Get the indexes of the fitted points and unfitted points\n",
    "            for i in np.arange(nObservations):\n",
    "                if (pyo.value(instance.zPlus[i+1]) + pyo.value(instance.zMinus[i+1])) == 0:\n",
    "                    indexesOfFittedPoints.append(i)\n",
    "                else:\n",
    "                    indexesOfUnfittedPoints.append(i)\n",
    "            #print('len(indexesOfFittedPoints)2: ', len(indexesOfFittedPoints))\n",
    "            #print('indexesOfFittedPoints: ', indexesOfFittedPoints, 'indexesOfUnfittedPoints: ', indexesOfUnfittedPoints)\n",
    "                \n",
    "            # Get the dual variable values with the following code\n",
    "            #Find the differential by summing up the dual variable values corresponding the unfitted point indexes.\n",
    "            # c[index]: is the name of the indexth constraint\n",
    "            # modelX.dual[<constraint name>]: gets the dual variable value for the indexth constraint\n",
    "            # c: is the parent name for the constraints set. It is also a list containing other constraint names and may be more.\n",
    "            # c is an interesting object, it is a list containing constraint names, it is also a range list of the indexes of the constraints.\n",
    "            dualVariableValuesFittedPoints=[]\n",
    "            differential=0\n",
    "            for c in instance.component_objects(pyo.Constraint, active=True):\n",
    "                for index in c:\n",
    "                    if index-1 in indexesOfFittedPoints:\n",
    "                        dualVariableValuesFittedPoints.append(instance.dual[c[index]])\n",
    "                    else:\n",
    "                        differential+=instance.dual[c[index]]\n",
    "            #print('len(indexesOfFittedPoints)3: ', len(indexesOfFittedPoints))\n",
    "            #print('indexesOfFittedPoints: ', indexesOfFittedPoints)\n",
    "            differentialListWhenArrivalIsNotInert.append(differential)\n",
    "            differentialList.append(differential)\n",
    "            #print('index: ', index, 'differential: ', differential, 'positionOfArrival: ', positionOfArrival, 'inert? : ', inertResult)\n",
    "\n",
    "            #Get the L1 regression hyperplane parameters - beta values \n",
    "            betaValues=[]\n",
    "            for i in nDimensionRange:\n",
    "                betaValues.append(pyo.value(instance.betaValues[i+1]))            \n",
    "                \n",
    "            \n",
    "            #Find the inverse of the basisX1\n",
    "            dfBasisX1=dfStreaming.iloc[indexesOfFittedPoints].copy()\n",
    "            dfBasisX1['Response']=1\n",
    "            df_BasisX1_inv =np.linalg.pinv(dfBasisX1)\n",
    "            \n",
    "\n",
    "        else:\n",
    "            #The arrival is inert, update the relevant lists.\n",
    "            inertRunAmount+=1\n",
    "            differential+=positionOfArrival\n",
    "            differentialList.append(differential)\n",
    "            #print('index: ', index, 'differential: ', differential, 'positionOfArrival: ', positionOfArrival, 'inert? : ', inertResult)            \n",
    "    \n",
    "\n",
    "    inertRunList.append(inertRunAmount)        \n",
    "    functionEndTime=time.perf_counter()\n",
    "    functionRunTime=functionEndTime-functionStartTime\n",
    "    inertPointPercentage = (len(dfNotStreamed)-len(notInertPointIndexes))/len(dfNotStreamed)\n",
    "    functionReturn={'functionRunTime': functionRunTime, 'notInertPointIndexes': notInertPointIndexes,\\\n",
    "                    'inertPointPercentage': inertPointPercentage, 'differentialList': differentialList,\\\n",
    "                   'differentialListWhenArrivalIsNotInert': differentialListWhenArrivalIsNotInert,\\\n",
    "                   'inertRunList': inertRunList}\n",
    "    return functionReturn , results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ec781",
   "metadata": {},
   "source": [
    "# =========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273f6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive online L1 regression is started\n",
      "streamingL1RegressionColdStartPyomo is initiated\n",
      "lenOriginal:  414 dimensionL1:  7\n"
     ]
    }
   ],
   "source": [
    "#Put the example data in the same folder as this .ipynb file.\n",
    "#The example data is: RealEstateValuationData.xlsx\n",
    "#APPLY EXPERIMENTS ON A DATA SET\n",
    "#Babayaga\n",
    "experimentStartTime=time.perf_counter()\n",
    "\n",
    "listColdStartTimeFunction=[]\n",
    "listColdInertTimeFunction=[]\n",
    "listColdvsColdInertFunction=[]\n",
    "inertPointPercentageList=[]\n",
    "nonInertPointIndexList=[]\n",
    "nList=[]\n",
    "mList=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print('newPath: ', newPath)\n",
    "dataName='RealEstateValuationData.xlsx'\n",
    "dfOriginal=pd.read_excel(dataName)\n",
    "#Test this shuffeling method (resets the point indexes)\n",
    "#dfOriginal = dfOriginal.sample(frac=1).reset_index(drop=True)\n",
    "#As well as this\n",
    "#dfOriginal = dfOriginal.sample(frac=1)\n",
    "#number of points\n",
    "n=np.shape(dfOriginal)[0]\n",
    "#dimension\n",
    "m=np.shape(dfOriginal)[1]\n",
    "#\n",
    "nList.append(n)\n",
    "mList.append(m)\n",
    "\n",
    "#Create a string parameter --> SpeedTest + <file name>\n",
    "#Do speed tests\n",
    "\n",
    "print('naive online L1 regression is started')\n",
    "resultStreamingColdStart, resultsColdStart = streamingL1RegressionColdStartPyomo(dfOriginal)\n",
    "print('naive online L1 regression is done')\n",
    "resultStreamingColdInert, resultsColdInert= streamingL1RegressionColdInertPyomo(dfOriginal)\n",
    "print('online L1 regression with inertness test is done')\n",
    "\n",
    "listColdStartTimeFunction.append(resultStreamingColdStart['functionRunTime'])\n",
    "listColdInertTimeFunction.append(resultStreamingColdInert['functionRunTime'])\n",
    "listColdvsColdInertFunction.append((resultStreamingColdStart['functionRunTime']-resultStreamingColdInert['functionRunTime'])/resultStreamingColdStart['functionRunTime'])\n",
    "inertPointPercentageList.append(resultStreamingColdInert['inertPointPercentage'])\n",
    "nonInertPointIndexList.append(resultStreamingColdInert['notInertPointIndexes'])\n",
    "\n",
    "        \n",
    "dfToAppend = pd.DataFrame ({'data names': 'WaterResourcesDataColumn1Excluded.csv',\\\n",
    "                            'cold start run (seconds) function time':listColdStartTimeFunction,\\\n",
    "                            'cold start + inert zones run (seconds) function time':listColdInertTimeFunction,\\\n",
    "                            '(cold start) vs (cold start + inert zones) (%100) function time':listColdvsColdInertFunction,\\\n",
    "                            'Inert point percent': inertPointPercentageList,\\\n",
    "                            'nonInertPointIndexList': nonInertPointIndexList,\\\n",
    "                            'n': nList,\\\n",
    "                            'm': mList\n",
    "                           }\n",
    "                          )\n",
    "\n",
    "#dfToAppend = pd.DataFrame(dictionaryToAppend)\n",
    "writer = pd.ExcelWriter(f'ExperimentResults{dataName}.xlsx' , engine='xlsxwriter')\n",
    "dfToAppend.to_excel(writer, index=True)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc74c4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
